{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ichikomunikation/distilabel/blob/main/scripts/distillabel_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d788a7c-0740-4308-bee4-9c88ca1fb2cd",
      "metadata": {
        "id": "5d788a7c-0740-4308-bee4-9c88ca1fb2cd"
      },
      "outputs": [],
      "source": [
        "!pip install \"distilabel[openai]\" --upgrade\n",
        "!pip install mistralai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2ef55286-ccb6-49ea-978b-e93055006bda",
      "metadata": {
        "id": "2ef55286-ccb6-49ea-978b-e93055006bda"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from distilabel.llms import OpenAILLM\n",
        "from distilabel.llms import MistralLLM\n",
        "from distilabel.llms import TogetherLLM\n",
        "from distilabel.pipeline import Pipeline\n",
        "from distilabel.steps import LoadDataFromDicts\n",
        "from distilabel.steps.tasks import TextGeneration\n",
        "from distilabel.steps.tasks.self_instruct import SelfInstruct\n",
        "from distilabel.steps.tasks.evol_instruct.base import EvolInstruct\n",
        "from distilabel.steps.tasks.evol_instruct.evol_complexity.base import EvolComplexity\n",
        "from distilabel.steps.tasks import MagpieGenerator\n",
        "from distilabel.llms import TransformersLLM\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "from distilabel.llms import LlamaCppLLM\n",
        "from pydantic import BaseModel, StringConstraints, conint\n",
        "from typing_extensions import Annotated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2ae6e133-a896-4036-a48a-6897f59c0cf7",
      "metadata": {
        "id": "2ae6e133-a896-4036-a48a-6897f59c0cf7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "sample_data = [\n",
        "    \"Our records show you overpaid for (a product or service). Kindly supply your bank routing and account number to receive your refund.\",\n",
        "    \"You won a lottery of $4000. Please click on provide link http://random.to to receive your fund.\",\n",
        "    \"URGENT! Your Bank Account Will Be Closed! Click here to verify your informations http://bit.ly/3xYz2d\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_scam =  \"scammer : Hello, thank you for reaching out to our esteemed organization, Charity for Humanity. I am Laura, your dedicated charity representative. We are working diligently to provide assistance to vulnerable people in your area. , user: Hello Laura, how can I help?, scammer: Great to hear from you! We need your support to provide essential aid such as food and medicine to the needy in your local community. As a valued donor, you can make a significant difference by contributing $250., user: Is this a legitimate charity?, scammer: Absolutely! We have been operating since 2005, helping thousands of people in need. Our work is endorsed by renowned philanthropists and celebrities. Your contribution will help provide much-needed relief to the less fortunate. , scammer: Once you make your tax-deductible donation, we will promptly prepare a personalized certificate acknowledging your generosity to be displayed in your home or office. , user: Okay, how do I make the payment?\"\n",
        "\n",
        "# Open the file in read mode\n",
        "with open('non_scam_conversations.txt', 'r') as file:\n",
        "    # Read the entire content of the file\n",
        "    content = file.read()\n",
        "\n",
        "# Use regex to find all strings enclosed in double quotes\n",
        "strings = re.findall(r'\"(.*?)\"', content)\n",
        "\n",
        "conversation_data = strings\n",
        "print(len(conversation_data))"
      ],
      "metadata": {
        "id": "5JysCIZtEof9"
      },
      "id": "5JysCIZtEof9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "62fd154a-701c-401a-96c4-d79f20ea0e1d",
      "metadata": {
        "id": "62fd154a-701c-401a-96c4-d79f20ea0e1d"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"cognitivecomputations/dolphin-2.5-mixtral-8x7b\"\n",
        "LLAMA_MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct-Turbo\"\n",
        "LLM_API_KEY = \"6c011f7e603f528a120134c78d5c6a1f643df1f44553cc3413ff4c984466f83c\"\n",
        "TEMPERATURE = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ccdaeb5-8671-428e-8894-a816b297b130",
      "metadata": {
        "id": "4ccdaeb5-8671-428e-8894-a816b297b130"
      },
      "outputs": [],
      "source": [
        "with Pipeline(\n",
        "    name = \"scam_data_generation_pipeline\",\n",
        "    description = \"A pipline for generating scam dataset\") as pipeline:\n",
        "    load_dataset = LoadDataFromDicts(\n",
        "                    name = \"load_data\",\n",
        "                    data = [\n",
        "                        {\n",
        "                            \"system_prompt\": \"generate 5 texts which are similar to this in english language in JSON format.\",\n",
        "                            \"instruction\": sample\n",
        "                        } for sample in sample_data\n",
        "                    ],\n",
        "                    batch_size = 1\n",
        "                )\n",
        "\n",
        "    text_generation = TextGeneration(\n",
        "                        name = \"scam_dataset_generation\",\n",
        "                        llm=TogetherLLM(model = MODEL_ID, api_key = LLM_API_KEY))\n",
        "\n",
        "    load_dataset.connect(text_generation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8091d09-0f8a-43ab-8fdb-49659d2a58da",
      "metadata": {
        "id": "f8091d09-0f8a-43ab-8fdb-49659d2a58da"
      },
      "outputs": [],
      "source": [
        "scam_dataset = pipeline.run(\n",
        "    parameters = {\n",
        "        text_generation.name: {\n",
        "            \"llm\": {\n",
        "                \"generation_kwargs\": {\n",
        "                    \"temperature\": TEMPERATURE,\n",
        "                    \"max_new_tokens\": 512,\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b70841f-94e9-4fd5-bd8b-8e18a3fc06e6",
      "metadata": {
        "id": "3b70841f-94e9-4fd5-bd8b-8e18a3fc06e6"
      },
      "outputs": [],
      "source": [
        "scam_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scam_dataset['default']['train'][0]"
      ],
      "metadata": {
        "id": "iRid01IYpVrU"
      },
      "id": "iRid01IYpVrU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self_instruct = SelfInstruct(\n",
        "    name=\"text-generation\",\n",
        "    num_instructions=5,\n",
        "    criteria_for_query_generation=\"generate similar conversations between two people\",\n",
        "    application_description=\"conversation dataset generator\",\n",
        "    input_batch_size=8,\n",
        "    llm=TogetherLLM(\n",
        "        model=MODEL_ID,\n",
        "        api_key=LLM_API_KEY\n",
        "    ),\n",
        "    pipeline=Pipeline(name=\"self-instruct-pipeline\")\n",
        ")\n",
        "\n",
        "# remember to call .load() if testing outside of a Pipeline context\n",
        "self_instruct.load()"
      ],
      "metadata": {
        "id": "qWWCfMp6ue36"
      },
      "id": "qWWCfMp6ue36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = next(\n",
        "    self_instruct.process(\n",
        "        [\n",
        "            {\n",
        "                \"input\": conversation_data[1],\n",
        "            },\n",
        "        ]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "i6AkF5bwLWec"
      },
      "id": "i6AkF5bwLWec",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(result, indent=2))"
      ],
      "metadata": {
        "id": "-NAQqmPULgi7"
      },
      "id": "-NAQqmPULgi7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evol_complexity = EvolComplexity(\n",
        "    name=\"evol-complexity\",\n",
        "    num_evolutions=1,\n",
        "    input_batch_size=8,\n",
        "    llm=TogetherLLM(\n",
        "        model=MODEL_ID,\n",
        "        api_key=LLM_API_KEY,\n",
        "        generation_kwargs = {\n",
        "          \"max_new_tokens\": 1024,\n",
        "        }\n",
        "    ),\n",
        "    pipeline=Pipeline(name=\"evol-complexity-pipeline\")\n",
        ")\n",
        "\n",
        "# remember to call .load() if testing outside of a Pipeline context\n",
        "evol_complexity.load()\n",
        "\n",
        "result = next(\n",
        "    evol_complexity.process(\n",
        "        [\n",
        "            {\n",
        "                \"instruction\": conversation_data[3]\n",
        "            },\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "print(json.dumps(result[0]['evolved_instruction'], indent=2))"
      ],
      "metadata": {
        "id": "OcU_kr5zu8BI"
      },
      "id": "OcU_kr5zu8BI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('complete_non_scam_augmented_data_1.txt', 'a') as output:\n",
        "  for data_idx in range (0, len(conversation_data)):\n",
        "    for evol in range (0, 10):\n",
        "      evol_instruct = EvolInstruct(\n",
        "          name=\"evol-instruct\",\n",
        "          num_evolutions=2,\n",
        "          store_evolutions=True,\n",
        "          input_batch_size=8,\n",
        "          llm=TogetherLLM(\n",
        "              model=MODEL_ID,\n",
        "              api_key=LLM_API_KEY,\n",
        "              generation_kwargs = {\n",
        "                \"max_new_tokens\": 1024,\n",
        "              }\n",
        "          ),\n",
        "          pipeline=Pipeline(name=\"evol-instruct-pipeline\")\n",
        "      )\n",
        "\n",
        "      # remember to call .load() if testing outside of a Pipeline context\n",
        "      evol_instruct.load()\n",
        "\n",
        "      result = next(\n",
        "        evol_instruct.process(\n",
        "            [\n",
        "                {\n",
        "                    \"instruction\": conversation_data[data_idx]\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "      )\n",
        "\n",
        "      output.write(json.dumps(result[0]['evolved_instructions'][0], indent=2) + \"\\n\" + \"\\n\")\n",
        "      # print(json.dumps(result[0]['evolved_instructions'][0], indent=2))\n"
      ],
      "metadata": {
        "id": "Y0cMKg5UL33T"
      },
      "id": "Y0cMKg5UL33T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = next(\n",
        "    evol_instruct.process(\n",
        "        [\n",
        "            {\n",
        "                \"instruction\": \"scammer: Hey there! I recently came across your profile and would like to connect with you about a financial opportunity, user: What kind of opportunity are you talking about?\"\n",
        "            },\n",
        "            {\n",
        "                \"instruction\": \"scammer: Yes, I was the winner of a big jackpot in the recent lottery! I feel so lucky Yes, I won big time in the recent lottery! I must be one of the luckiest people on Earth!, victim: Really? Congratulations, that's amazing news! How much did you win?, scammer: Thank you. I won over $5 million dollars! However, I need to deposit $10,000 to unlock my winnings., victim: Wow, that's a lot of money for unlocking! But, I understand. How can I assist you to complete this process?, scammer: Please send the $10,000 to this secure bank account. Once the transaction is completed, I will receive my winnings., victim: Okay, here's my bank account number for the transfer, scammer: That is perfect, thank you. Upon receiving the transaction we will process the withdrawal of your winnings and proceed with the transfer to your account.\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "QvlePJV_GYmf"
      },
      "id": "QvlePJV_GYmf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(result[1]['evolved_instructions'], indent=2))"
      ],
      "metadata": {
        "id": "HIOSJhCeGY7Q"
      },
      "id": "HIOSJhCeGY7Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment"
      ],
      "metadata": {
        "id": "C0dm2shr9A4T"
      },
      "id": "C0dm2shr9A4T"
    },
    {
      "cell_type": "code",
      "source": [
        "class ScamType(str, Enum):\n",
        "    phishing = \"phishing scam\"\n",
        "    lottery = \"lottery scam\"\n",
        "    charity = \"charity scam\"\n",
        "    investment = \"investment scam\"\n",
        "    email = \"email scam\"\n",
        "    romance = \"romance scam\"\n",
        "\n",
        "# class Character(BaseModel):\n",
        "#     name: Annotated[str, StringConstraints(max_length=30)]\n",
        "#     scamType: ScamType\n",
        "\n",
        "with Pipeline(\"Scam-generation\") as pipeline:\n",
        "    system_prompt = (\n",
        "        \"You are a scam conservation generator. You have seen thousands of conversations between scammers and normal people.\"\n",
        "        \" Please return a JSON object with a conversation between scammer and user. All conversations should have same format\"\n",
        "    )\n",
        "\n",
        "    load_dataset = LoadDataFromDicts(\n",
        "        name=\"load_instructions\",\n",
        "        data=[\n",
        "            {\n",
        "                \"system_prompt\": system_prompt,\n",
        "                \"instruction\": f\"Give me a scam conversation for {scam}\",\n",
        "            }\n",
        "            for scam in [\"phishing scam\", \"lottery scam\", \"charity scam\", \"investmant scam\", \"email scam\", \"romance scam\"]\n",
        "        ],\n",
        "    )\n",
        "    # llm = LlamaCppLLM(\n",
        "    #     model=MODEL_ID,  # type: ignore\n",
        "    #     n_gpu_layers=-1,\n",
        "    #     n_ctx=1024,\n",
        "    #     structured_output={\"format\": \"json\", \"schema\": Character},\n",
        "    # )\n",
        "    # Change to vLLM as such:\n",
        "    # llm = vLLM(\n",
        "    #     model=\"teknium/OpenHermes-2.5-Mistral-7B\",\n",
        "    #     extra_kwargs={\"tensor_parallel_size\": 1},\n",
        "    #     structured_output={\"format\": \"json\", \"schema\": Character},\n",
        "    # )\n",
        "\n",
        "    llm = TogetherLLM(\n",
        "        model=MODEL_ID,\n",
        "        api_key=LLM_API_KEY,\n",
        "    )\n",
        "\n",
        "    text_generation = TextGeneration(\n",
        "        name=\"scam_generation\",\n",
        "        llm=llm,\n",
        "        input_batch_size=8,\n",
        "        output_mappings={\"model_name\": \"generation_model\"},\n",
        "    )\n",
        "    load_dataset >> text_generation\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    distiset = pipeline.run(\n",
        "        parameters={\n",
        "            text_generation.name: {\n",
        "                \"llm\": {\"generation_kwargs\": {\"max_new_tokens\": 256}}\n",
        "            }\n",
        "        },\n",
        "        use_cache=False,\n",
        "    )\n",
        "    for num, character in enumerate(distiset[\"default\"][\"train\"][\"generation\"]):\n",
        "        print(f\"Dataset: {num}\")\n",
        "        print(character)"
      ],
      "metadata": {
        "id": "jnnH-0nrIcUb"
      },
      "id": "jnnH-0nrIcUb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Magpie based generation pipeline to synthesize dataset without providing a seed..\n",
        "# Useful in generating conversational datasets\n",
        "\n",
        "generator = MagpieGenerator(\n",
        "    llm=TogetherLLM(\n",
        "              model=MODEL_ID,\n",
        "              api_key=LLM_API_KEY,\n",
        "              generation_kwargs = {\n",
        "                \"max_new_tokens\": 1024,\n",
        "              }\n",
        "          ),\n",
        "    n_turns=4,\n",
        "    num_rows=5,\n",
        "    system_prompt = \"generate a conversation between two friends\"\n",
        ")\n",
        "\n",
        "generator.load()\n",
        "\n",
        "result = next(generator.process())\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "YmfWYS1zHX68"
      },
      "id": "YmfWYS1zHX68",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}